/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => AudioRecorderPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian = require("obsidian");
var path = __toESM(require("path"));
var DEFAULT_SETTINGS = {
  recordingsFolder: "Recordings",
  recordMicrophone: true,
  selectedMicrophoneId: "default"
};
var AudioRecorderPlugin = class extends import_obsidian.Plugin {
  constructor() {
    super(...arguments);
    this.recorder = null;
    this.chunks = [];
    this.recordingStream = null;
    this.micStream = null;
    this.audioContext = null;
    this.micGainNode = null;
    this.analyserNode = null;
    this.statusBarItem = null;
    this.activeFileAtStart = null;
    this.controlWindow = null;
    // BrowserWindow
    this.animationFrameId = null;
  }
  async onload() {
    await this.loadSettings();
    const ribbonIconEl = this.addRibbonIcon(
      "microphone",
      "Start/Stop Recording",
      (evt) => {
        this.toggleRecording();
      }
    );
    ribbonIconEl.addClass("audio-recorder-ribbon-class");
    this.statusBarItem = this.addStatusBarItem();
    this.statusBarItem.setText("");
    this.addCommand({
      id: "start-stop-recording",
      name: "Start/Stop Recording",
      callback: () => {
        this.toggleRecording();
      }
    });
    this.addSettingTab(new AudioRecorderSettingTab(this.app, this));
  }
  onunload() {
    this.stopRecording();
  }
  async toggleRecording() {
    if (this.recorder && this.recorder.state === "recording") {
      this.stopRecording();
    } else {
      this.startRecording();
    }
  }
  async startRecording() {
    var _a;
    try {
      this.activeFileAtStart = this.app.workspace.getActiveFile();
      const electron = require("electron");
      let desktopCapturer = electron.desktopCapturer;
      let remote = electron.remote;
      if (!desktopCapturer && remote) {
        desktopCapturer = remote.desktopCapturer;
      }
      if (!desktopCapturer) {
        new import_obsidian.Notice("Error: desktopCapturer API is not available.");
        return;
      }
      const sources = await desktopCapturer.getSources({ types: ["screen"] });
      if (sources.length === 0) {
        new import_obsidian.Notice("No screen sources found.");
        return;
      }
      const source = sources[0];
      const systemStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          mandatory: {
            chromeMediaSource: "desktop",
            chromeMediaSourceId: source.id
          }
        },
        video: {
          mandatory: {
            chromeMediaSource: "desktop",
            chromeMediaSourceId: source.id
          }
        }
      });
      const systemAudioTracks = systemStream.getAudioTracks();
      if (systemAudioTracks.length === 0) {
        new import_obsidian.Notice(
          "No system audio track captured. Ensure you are on Windows or have system audio setup."
        );
      }
      this.recordingStream = systemStream;
      if (this.settings.recordMicrophone) {
        try {
          const constraints = { audio: true };
          if (this.settings.selectedMicrophoneId && this.settings.selectedMicrophoneId !== "default") {
            constraints.audio = {
              deviceId: { exact: this.settings.selectedMicrophoneId }
            };
          }
          this.micStream = await navigator.mediaDevices.getUserMedia(constraints);
        } catch (micErr) {
          console.error("Error capturing microphone:", micErr);
          new import_obsidian.Notice(
            "Failed to capture microphone. Recording system audio only."
          );
        }
      }
      let finalStream;
      this.audioContext = new AudioContext();
      const destination = this.audioContext.createMediaStreamDestination();
      const masterGain = this.audioContext.createGain();
      masterGain.connect(destination);
      this.analyserNode = this.audioContext.createAnalyser();
      this.analyserNode.fftSize = 128;
      this.analyserNode.smoothingTimeConstant = 0.5;
      masterGain.connect(this.analyserNode);
      if (systemAudioTracks.length > 0) {
        const systemSource = this.audioContext.createMediaStreamSource(systemStream);
        systemSource.connect(masterGain);
      }
      if (this.micStream) {
        const micSource = this.audioContext.createMediaStreamSource(
          this.micStream
        );
        this.micGainNode = this.audioContext.createGain();
        this.micGainNode.gain.value = 1;
        micSource.connect(this.micGainNode);
        this.micGainNode.connect(masterGain);
      }
      finalStream = destination.stream;
      if (finalStream.getAudioTracks().length === 0) {
        new import_obsidian.Notice("No audio tracks available to record.");
        this.stopRecordingStreams();
        return;
      }
      this.recorder = new MediaRecorder(finalStream, {
        mimeType: "audio/webm"
      });
      this.chunks = [];
      this.recorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          this.chunks.push(e.data);
        }
      };
      this.recorder.onstop = async () => {
        var _a2;
        const blob = new Blob(this.chunks, { type: "audio/webm" });
        await this.saveRecording(blob);
        this.stopRecordingStreams();
        (_a2 = this.statusBarItem) == null ? void 0 : _a2.setText("");
        new import_obsidian.Notice("Recording saved.");
        this.closeControlWindow();
      };
      this.recorder.start();
      (_a = this.statusBarItem) == null ? void 0 : _a.setText("Recording...");
      new import_obsidian.Notice("Recording started.");
      this.openControlWindow(electron);
      this.startAudioVisualization();
    } catch (err) {
      console.error("Error starting recording:", err);
      new import_obsidian.Notice("Failed to start recording. See console for details.");
      this.stopRecordingStreams();
    }
  }
  openControlWindow(electron) {
    const remote = electron.remote || electron;
    const BrowserWindow = remote.BrowserWindow;
    const ipcMain = remote.ipcMain;
    const { width, height } = remote.screen.getPrimaryDisplay().workAreaSize;
    this.controlWindow = new BrowserWindow({
      width: 320,
      height: 110,
      frame: false,
      transparent: true,
      backgroundColor: "#00000000",
      // Force transparency
      hasShadow: false,
      // Disable native shadow to prevent black corners
      alwaysOnTop: true,
      resizable: false,
      webPreferences: {
        nodeIntegration: true,
        contextIsolation: false
      },
      x: Math.floor(width / 2 - 160),
      y: height - 110
    });
    const pluginDir = this.app.vault.adapter.basePath + "/" + this.manifest.dir;
    const htmlPath = path.join(pluginDir, "control-window.html");
    this.controlWindow.loadFile(htmlPath);
    this.controlWindow.webContents.on("did-finish-load", () => {
      const accentColor = getComputedStyle(document.body).getPropertyValue(
        "--interactive-accent"
      ) || "#7c3aed";
      this.controlWindow.webContents.send("set-accent-color", accentColor);
    });
    const onMuteMic = () => {
      if (this.micGainNode)
        this.micGainNode.gain.value = 0;
    };
    const onUnmuteMic = () => {
      if (this.micGainNode)
        this.micGainNode.gain.value = 1;
    };
    const onStopRecording = () => {
      this.stopRecording();
    };
    ipcMain.on("mute-mic", onMuteMic);
    ipcMain.on("unmute-mic", onUnmuteMic);
    ipcMain.on("stop-recording", onStopRecording);
    this.controlWindow.on("closed", () => {
      ipcMain.removeListener("mute-mic", onMuteMic);
      ipcMain.removeListener("unmute-mic", onUnmuteMic);
      ipcMain.removeListener("stop-recording", onStopRecording);
      this.controlWindow = null;
    });
  }
  closeControlWindow() {
    if (this.controlWindow) {
      this.controlWindow.close();
      this.controlWindow = null;
    }
    if (this.animationFrameId) {
      cancelAnimationFrame(this.animationFrameId);
      this.animationFrameId = null;
    }
  }
  startAudioVisualization() {
    if (!this.analyserNode || !this.controlWindow)
      return;
    const dataArray = new Uint8Array(this.analyserNode.frequencyBinCount);
    const update = () => {
      if (!this.analyserNode || !this.controlWindow)
        return;
      this.analyserNode.getByteFrequencyData(dataArray);
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += dataArray[i];
      }
      const average = sum / dataArray.length / 255;
      if (!this.controlWindow.isDestroyed()) {
        this.controlWindow.webContents.send("audio-level", average);
      }
      this.animationFrameId = requestAnimationFrame(update);
    };
    update();
  }
  stopRecording() {
    if (this.recorder && this.recorder.state === "recording") {
      this.recorder.stop();
    }
  }
  stopRecordingStreams() {
    if (this.recordingStream) {
      this.recordingStream.getTracks().forEach((track) => track.stop());
      this.recordingStream = null;
    }
    if (this.micStream) {
      this.micStream.getTracks().forEach((track) => track.stop());
      this.micStream = null;
    }
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    this.recorder = null;
  }
  async saveRecording(blob) {
    const arrayBuffer = await blob.arrayBuffer();
    const buffer = new Uint8Array(arrayBuffer);
    const folderPath = this.settings.recordingsFolder;
    if (!await this.app.vault.adapter.exists(folderPath)) {
      await this.app.vault.createFolder(folderPath);
    }
    const now = new Date();
    const timestamp = `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, "0")}-${now.getDate().toString().padStart(2, "0")} ${now.getHours().toString().padStart(2, "0")}.${now.getMinutes().toString().padStart(2, "0")}.${now.getSeconds().toString().padStart(2, "0")}`;
    const filename = `${folderPath}/Recording ${timestamp}.webm`;
    const file = await this.app.vault.createBinary(filename, buffer);
    if (this.activeFileAtStart) {
      const linkText = `
![[${file.path}]]
`;
      await this.app.vault.append(this.activeFileAtStart, linkText);
    }
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
};
var AudioRecorderSettingTab = class extends import_obsidian.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Settings for Audio Recorder" });
    new import_obsidian.Setting(containerEl).setName("Recordings Folder").setDesc("Folder to save audio recordings in").addText(
      (text) => text.setPlaceholder("Recordings").setValue(this.plugin.settings.recordingsFolder).onChange(async (value) => {
        this.plugin.settings.recordingsFolder = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Record Microphone").setDesc("Record microphone audio along with system audio.").addToggle(
      (toggle) => toggle.setValue(this.plugin.settings.recordMicrophone).onChange(async (value) => {
        this.plugin.settings.recordMicrophone = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian.Setting(containerEl).setName("Microphone Source").setDesc("Select the microphone to record.").addDropdown(async (dropdown) => {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter((d) => d.kind === "audioinput");
      audioInputs.forEach((device) => {
        dropdown.addOption(
          device.deviceId,
          device.label || `Microphone ${device.deviceId}`
        );
      });
      dropdown.setValue(this.plugin.settings.selectedMicrophoneId);
      dropdown.onChange(async (value) => {
        this.plugin.settings.selectedMicrophoneId = value;
        await this.plugin.saveSettings();
      });
    });
  }
};
